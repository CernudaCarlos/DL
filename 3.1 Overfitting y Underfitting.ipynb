{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting y underfitting\n",
    "\n",
    "En todos los ejemplos anteriores hemos comprobado que el rendimiento de los modelos presentan un máximo en los datos de validación tras unas pocas epochs y comienza a degradarse, es decir, que los modelos comienzan a *sobreajustarse* a los datos de entrenamiento sin que haya dado tiempo a extraer patrones suficientemente útiles de los datos de entrenamiento. El sobreajuste sucede en todos los problemas de ML, así que aprender a manejarlo es esencial para controlar las técnicas de ML.\n",
    "\n",
    "El problema fundamental de ML es la tensión existente entre optimización y generalización, donde la \"optimización\" es respecto al proceso de ajustar un modelo para conseguir el mejor rendimiento posible sobre los datos de entrenamiento (la sección de \"aprendizaje\" en Aprendizaje Automático), y la \"generalizacion\" es respecto a lo bien que el modelo entrenado se comporta sobre datos que no ha visto anteriormente. El objetivo es conseguir una buena generalización, pero es la parte que no podemos controlar, solo podemos ajustar el modelo en función los datos de entrenamiento.\n",
    "\n",
    "Al principio del entrenamiento, la optimización y le generalización están correladas: cuanto menor es el error sobre los datos de entrenamiento, menor es sobre os datos de test. Mientras sucede esto, el modelo se dice que _under-fit_, lo que quiere decir que todavía se puede progresar, porque la red todavía no ha modelado todos los patrones relevantes existentes en los datos de entrenamiento. Pero tras un cierto número de iteraciones sobre los datos de entrenamiento, la generalización deja de mejorar, y las métricas de validación empiezan a degradarse: el modelo comienza a *sobreajustarse*, lo que quiere decir que compienza a aprender patrones que son específicos de los datos de entrenamiento pero que son erróneos, o son irrelevantes, en datos nuevos.\n",
    "\n",
    "Para prevenir que un modelo aprenda patrones irrelevantes o erróneos de los datos de entrenamiento, la mejor solución, por supuesto, es conseguir más, y variados, datos de entrenamiento. Un modelo entrenado en más datos, generalizará mejor... pero no siempre es posible conseguir más datos. En este caso, una buena solución es acotar la cantidad de información que el modelo puede almacenar, o añadir restricciones a qué tipo de información se puede almacenar. Si una red solo puede memorizar un pequeño número de patrones, el proceso de optimización forzará al modelo a enfocarse en los patrones más importantes, aquellos que que tienen más opciones de generalizar bien.\n",
    "\n",
    "El proceso de luchar contra el sobreajuste se conoce como *regularización*. En este módulo vamos a revisar algunas de las técnicas más comunes de regularización y aplicarlas de forma práctica para mejorar el modelo de clasificación de opiniones de películas que vimos anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a preparar los datos usados en el módulo anterior para reutilizarlos ahora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "import numpy as np\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    # Create an all-zero matrix of shape (len(sequences), dimension)\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.  # set specific indices of results[i] to 1s\n",
    "    return results\n",
    "\n",
    "# Our vectorized training data\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# Our vectorized test data\n",
    "x_test = vectorize_sequences(test_data)\n",
    "# Our vectorized labels\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Luchando contra el Sobreajuste\n",
    "\n",
    "## Reduciendo el tamaño de la red\n",
    "\n",
    "La forma más sencilla de evitar el sobreajuste es reducir el tamaño del modelo, es decir, el número de parámetros aprendibles en el modelo (que se determina por el número de capas y el número de unidades por capa). En el aprendizaje profundo, el número de parámetros aprendibles en un modelo se denomina a menudo \"capacidad\" del modelo. Intuitivamente, un modelo con más parámetros tendrá más \"capacidad de memorización\" y por lo tanto podrá aprender fácilmente un diccionario que asocia perfectamente las muestras de entrenamiento y sus objetivos. Una asociación que no tiene posibilidades de generalizar. Por ejemplo, un modelo con 500.000 parámetros binarios podría fácilmente aprender la clase de cada dígito en el problema MNIST: sólo necesitaríamos 10 parámetros binarios para cada uno de los 50.000 dígitos. Un modelo de este tipo sería inútil para clasificar nuevas muestras de dígitos, porque no ha extraido patrones, solo memorizado los datos. Hay que tener presente lo siguiente: los modelos de aprendizaje profundo tienden a ser buenos para adaptarse a los datos de entrenamiento, pero el verdadero desafío es la generalización, no el ajuste perfecto.\n",
    "\n",
    "Por otro lado, si la red tiene recursos de memorización limitados, no podrá aprender esta asociación tan fácilmente, y por lo tanto, para minimizar su pérdida, tendrá que recurrir al aprendizaje de representaciones comprimidas que tengan poder de predicción sobre los objetivos. Este es precisamente el tipo de representaciones que interesa. Al mismo tiempo, ha de tenerse en cuenta que se deben utilizar modelos que tengan suficientes parámetros para que la complejidad de la estructura aprendida por el modelo no sea demasiado baja, Es decir, hay que llegar a un compromiso entre \"demasiada capacidad\" e \"insuficiente capacidad\".\n",
    "\n",
    "Desafortunadamente, no existe una fórmula mágica para determinar cuál es el número correcto de capas, o cuál es el tamaño correcto para cada capa, por lo que habrá que evaluar una colección de arquitecturas diferentes para encontrar el tamaño de modelo adecuado a los datos. El flujo de trabajo general para encontrar un tamaño de modelo apropiado es comenzar con relativamente pocas capas y aumentar el tamaño de las capas, o añadir nuevas capas, hasta que se obtenga un rendimiento decreciente con respecto a la pérdida en validación (no en entrenamiento).\n",
    "\n",
    "Probemos esto en nuestra red de clasificación de opiniones de películas. La red original era:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "original_model = models.Sequential()\n",
    "original_model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "original_model.add(layers.Dense(16, activation='relu'))\n",
    "original_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "original_model.compile(optimizer='rmsprop',\n",
    "                       loss='binary_crossentropy',\n",
    "                       metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos comentado, comenzamos reduciendo el tamaño de la red:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_model = models.Sequential()\n",
    "smaller_model.add(layers.Dense(4, activation='relu', input_shape=(10000,)))\n",
    "smaller_model.add(layers.Dense(4, activation='relu'))\n",
    "smaller_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "smaller_model.compile(optimizer='rmsprop',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Vamos a comparar los resultados de pérdida en validación de ambas redes (recuerda; menor périda de validación, mejor es el modelo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_hist = original_model.fit(x_train, y_train,\n",
    "                                   epochs=20,\n",
    "                                   batch_size=512,\n",
    "                                   validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_model_hist = smaller_model.fit(x_train, y_train,\n",
    "                                       epochs=20,\n",
    "                                       batch_size=512,\n",
    "                                       validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, 21)\n",
    "original_val_loss = original_hist.history['val_loss']\n",
    "smaller_model_val_loss = smaller_model_hist.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# b+ is for \"blue cross\"\n",
    "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, smaller_model_val_loss, 'bo', label='Smaller model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Como se puede observar, la red pequeña comienza a sobreajustar más tarde que la original (tras 6 epochs, en vez de 4) y su rendimiento se degrada mucho más lentamente cuando esto sucede.\n",
    "\n",
    "Ahora, por probrar, vamos a añadir una red con mucha más capacidad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigger_model = models.Sequential()\n",
    "bigger_model.add(layers.Dense(512, activation='relu', input_shape=(10000,)))\n",
    "bigger_model.add(layers.Dense(512, activation='relu'))\n",
    "bigger_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "bigger_model.compile(optimizer='rmsprop',\n",
    "                     loss='binary_crossentropy',\n",
    "                     metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigger_model_hist = bigger_model.fit(x_train, y_train,\n",
    "                                     epochs=20,\n",
    "                                     batch_size=512,\n",
    "                                     validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ponerla también en comparación con la original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigger_model_val_loss = bigger_model_hist.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
    "plt.plot(epochs, bigger_model_val_loss, 'bo', label='Bigger model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La red grande comienza a sobreajustar desde el principio, tras una única epoch, y el sobreajuste es mucho más severo. Su pérdida de validación presenta también mucho más ruido.\n",
    "\n",
    "Y las pérdidas de entrenamiento son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_loss = original_hist.history['loss']\n",
    "bigger_model_train_loss = bigger_model_hist.history['loss']\n",
    "\n",
    "plt.plot(epochs, original_train_loss, 'b+', label='Original model')\n",
    "plt.plot(epochs, bigger_model_train_loss, 'bo', label='Bigger model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que la red grande consigue que su pérdida de entrenamiento sea prácticamente nula muy rápido. Cuanto mayor es la capacidad de la red, más rápido modela los datos de entrenamiento a la perfección, pero más susceptible es al sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Añadiendo regularización a los pesos\n",
    "\n",
    "Principio de _la navaja de Occam_: \"si se dan dos explicaciones para algo, la explicación correcta más probable es la más simple, la que hace el menor número de suposiciones\". \n",
    "\n",
    "Como método que aspira a ser estándar en el avance del conocimiento, este mismo principio también se aplica a los modelos aprendidos por las redes neuronales: fijados datos de entrenamiento y una arquitectura de red, hay múltiples conjuntos de valores de pesos (lo que se traduce en múltiples _modelos_) que podrían explicar los datos, y los modelos más sencillos tienen menos probabilidades de sobreajustar que los complejos.\n",
    "\n",
    "Un \"modelo simple\" en este contexto es un modelo en el que la distribución de valores de los parámetros tiene menos entropía (o un modelo que tiene en total menos parámetros, como vimos en la sección anterior). Por lo tanto, una forma común de mitigar el sobreajuste es poner límites a la complejidad de la red forzando a sus pesos a tomar sólo valores pequeños, lo que hace que la distribución de estos valores sea más \"regular\". A este procedimiento, en general, se le llama \"regularización de los pesos\", y se consigue añadiendo a la función de pérdida de la red un _coste_ asociado a tener grandes pesos. Este  coste extra suele venir dado de dos formas fundamentalmente:\n",
    "\n",
    "\n",
    "* Regularización L1: el coste es proporcional al _valor absoluto de los pesos_ (la norma L1 de los pesos).\n",
    "* Regularización L2: el coste es proporcional al _cuadrado de los valores delos pesos_ (la normal L2 de los pesos). En el contexto de las redes neuronales, a esta nocrma también se le llama _weight decay_.\n",
    "\n",
    "En Keras, la regularización de los pesos se añade pasando instancias adecuadas de regularizadores a las capas por medio de argumentos específicos. Por ejemplo, si quisiéramos añadir una regularización L2 al modelo anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "l2_model = models.Sequential()\n",
    "l2_model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),\n",
    "                          activation='relu', input_shape=(10000,)))\n",
    "l2_model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),\n",
    "                          activation='relu'))\n",
    "l2_model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_model.compile(optimizer='rmsprop',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`l2(0.001)` significa que cada coeficiente de la matriz de pesos de la capa añadirá `0.001 * weight_coefficient_value` al valor de pérdida total de la red. Debe tenerse en cuenta que como esta penalización solo se aplica en tiempo de entrenamiento, la pérdida que se obtiene al regularizar es mucho mayor para el entrenamiento que para el test.\n",
    "\n",
    "EL impacto de esta reguarización en nuestro ejemplo sería:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_model_hist = l2_model.fit(x_train, y_train,\n",
    "                             epochs=20,\n",
    "                             batch_size=512,\n",
    "                             validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_model_val_loss = l2_model_hist.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
    "plt.plot(epochs, l2_model_val_loss, 'bo', label='L2-regularized model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Como se puede observar, el modelo con L2 se ha hecho mucho más resistente al sobreajuste que el original, incluso teniendo el mismo número de parámetros.\n",
    "\n",
    "En Keras, puedes usar la L2, la L1, e incluso una combinación de ambas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "# L1 regularization\n",
    "regularizers.l1(0.001)\n",
    "\n",
    "# L1 and L2 regularization at the same time\n",
    "regularizers.l1_l2(l1=0.001, l2=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Añadiendo Dropout\n",
    "\n",
    "_Dropout_ es una de las técnicas de regularización más efectivas y más comúnmente utilizadas para las redes neuronales, desarrollada por Hinton y su equipo de estudiantes de la Universidad de Toronto. El Dropout, aplicado a una capa, consiste en la \"eliminación\" aleatoria (es decir, poner a cero) de un número de características de salida de la capa durante el entrenamiento. \n",
    "\n",
    "Supongamos que una capa devolviese un vector `[0.2, 0.5, 1.3, 0.8, 1.1]` para una de las muestras de entrada durante el entrenamiento; después de aplicar dropout, este vector tendrá unas cuantas entradas nulas distribuidas al azar, por ejemplo, `[0, 0.5, 1.3, 0, 1.1]`. La \"tasa de dropout\" es la fracción de las características que se ponen a cero; normalmente se ajusta entre 0,2 y 0,5. Durante la fase de  test no se hace dropout, sino que los valores de salida de la capa se reducen en un factor igual al dropout, con el fin de equilibrar el hecho de que hay más unidades activas que durante el entrenamiento.\n",
    "\n",
    "Es decir, si durante el entrenamiento el resultado es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At training time: we drop out 50% of the units in the output\n",
    "layer_output *= np.randint(0, high=2, size=layer_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Durante el test el proceso es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At test time:\n",
    "layer_output *= 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Este proceso se puede implementar haciendo ambas operaciones durante el tiempo de entrenamiento, de forma que no es necesario considerarlo en el momento del test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At training time:\n",
    "layer_output *= np.randint(0, high=2, size=layer_output.shape)\n",
    "# Note that we are scaling *up* rather scaling *down* in this case\n",
    "layer_output /= 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Pero, ¿porqué esta técnica reduce el sobreajuste? La idea central es que la introducción de ruido en los valores de salida de una capa puede romper patrones de azar que no son significativos, y que la red empezaría a memorizar si no hubiera ruido presente. \n",
    "\n",
    "En Keras se pueden introducir procesos de dropout por medio de capas `Dropout` que se aplican a las salidas de la capa anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dropout(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduzcamos dos capas `Dropout` en el modelo anterior para ver si reducen el sobreajuste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpt_model = models.Sequential()\n",
    "dpt_model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "dpt_model.add(layers.Dropout(0.5))\n",
    "dpt_model.add(layers.Dense(16, activation='relu'))\n",
    "dpt_model.add(layers.Dropout(0.5))\n",
    "dpt_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "dpt_model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpt_model_hist = dpt_model.fit(x_train, y_train,\n",
    "                               epochs=20,\n",
    "                               batch_size=512,\n",
    "                               validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y comparemos los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpt_model_val_loss = dpt_model_hist.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
    "plt.plot(epochs, dpt_model_val_loss, 'bo', label='Dropout-regularized model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De nuevo, se observa una clara mejoría respecto de la red original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "En resumen, las formas más comunes de prevenir el sobreajuste en redes neuronales son:\n",
    "\n",
    "* Conseguir más (y más variados) datos de entrenamiento.\n",
    "* Reducir la capacidad de la red (número de parámetros).\n",
    "* Añadir regularización a los pesos (penilzando configuraciones con pesos muy grandes).\n",
    "* Añadir dropout (añadir ruido con ceros)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
