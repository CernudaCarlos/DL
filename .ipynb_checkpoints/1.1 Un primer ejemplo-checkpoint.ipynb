{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primer ejemplo con Keras + Python\n",
    "\n",
    "Este es nuestro primer [Jupyter Notebook](http://jupyter.org) de Deep Learning con [Keras](https://keras.io) (y Python). \n",
    "\n",
    "En este primer notebook únicamente mostraremos un ejemplo de red neuronal con un par de capas que aborda el famoso problema MNIST. El objetivo es simplemente ver el flujo de trabajo habitual para atacar un problema con Keras, pero no nos detendremos en los detalles de cómo se usa Keras ni de la potencia que podemos extraer a las diversas funcionalidades que proporciona. En notebooks posteriores profundizaremos en su uso y en las características propias de Deep Learning que podemos abordar.\n",
    "\n",
    "Para ejecutar los diversos chunks (así se llaman) de código que conforman este notebook puedes pulsar en el botón *Run* que puedes encontrar en cada uno de ellos, o bien situando el cursor dentro del chunk y presionando la comnbinación *Shift+Enter* (también tienes la opción de usar las opciones de ejecución en el menú *Run* de la barra del navegador Jupyter. Ten en cuenta que algunas opciones pueden cambiar dependiendo del entorno en el que estés trabajando con este notebook (Jupyter Notebook, Jupyter Lab, o Collab de Google.. cualquiera de los tres funcionan de forma similar, pero con ligeras diferencias). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuestro primer modelo con Keras\n",
    "\n",
    "El primer paso es cargar la librería keras que permitirá interactuar a Python con la librería de Deep Learning que usemos (en nuestro caso, [Tensorflow](https://www.tensorflow.org))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 2757388288108368353\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3230918246\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 12369717276712349432\n",
      "physical_device_desc: \"device: 0, name: GeForce 940MX, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación de los datos\n",
    "\n",
    "A continuación vamos a cargar los datos del problema [MNIST](https://en.wikipedia.org/wiki/MNIST_database), una gran base de datos de dígitos escritos a mano que sevirá como primera aproximación a la resolución de un problema de clasificación haciendo uso de Redes Neuronales.\n",
    "\n",
    "Afortunadamente, este problema es tan común que Keras proporciona una instrucción directa para descargar las imágenes (de 28x28 pixels en escala de grises) que representan los miles de dígitos escritos a mano. El paso, que veremos que es habitual en muchos problemas que veremos en el curso, consta de dos pasos: primero cargar la librería de Keras que prporciona las herramientas para trabajar con el dataset concreto (que comúnmente están en el paquete `keras.datasets`, y después ejecutar el proceso de carga de los datos (que serán descargados la primera vez desde un repositorio que viene por defecto predefinido en ese paquete):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observa que el proceso de carga de datos separa adecuadamente las diversas partes de que consta este dataset:  (conjunto de entrenamiento, conjunto de test), y cada uno de estos conjuntos está formado por un conjunto de imágenes, con sus respectivas etiquetas de clasificación (*labels*).\n",
    "\n",
    "Podemos explorar un poco cómo son cada una de estas variables haciendo uso de instrucciones específicas de Python que nos dan información acerca de su estructura y muestra los primeros valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De forma análoga, podemos explorar las imágenes que se usarán para test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos ver alguna de las imágenes que hay en el dataset, podemos hacer uso de la instrucción adecuada de, por ejemplo, la librería `matplotlib`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def gen_image(arr):\n",
    "    conv = (np.reshape(arr, (28, 28)) * 255).astype(np.uint8)\n",
    "    plt.imshow(conv, interpolation='nearest')\n",
    "    return plt\n",
    "\n",
    "gen_image(test_images[0]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El flujo de trabajo es similar al que se sigue siempre en los procesos de ML Supervisado: mostramos al modelo (una red neuronal, en nuestro caso) los datos de *entrenamiento*, `train_images` y `train_labels`; el modelo debe *aprender* a asociar las imágenes con las etiquetas asociadas; Por último, verificamos el aprendizaje realizado comprobando sobre `test_images` que las respuestas dadas por el modelo (*predicciones*) coinciden con las almacenadas en `test_labels`.\n",
    "\n",
    "Ya estamos en condiciones de definir nuestra primera red neuronal (muy básica, con solo una capa de entrada y una de salida) que consumirá los datos anteriores para ver si somos capaces de dar una primera solución al problema del reconocimiento de dígitos manuscritos.\n",
    "\n",
    "En nuestro caso, vamos a situar una capa de entrada con 784 (= 28 * 28) neuronas (que recibirán cada uno de los 784 pixels de cada imagen), con función de activación ReLU, y una capa de salida con 10 neuronas (para cada una de las posibles etiquetas de salida), y con activación softmax (por lo que se podrá interpretar como una probabilidad de salida que indica lo probable que es que la imagen de entrada tenga cada una de las etiquetas como salida):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "El elemento básico de las redes neuronales es lo que se conoce como *capa* (*layer*), un módulo de procesamiento de datos que se puede ver como un \"filtro\" de datos. Como veremos más adelante, las capas extraen *representaciones* de los datos que reciben, que se espera que sean más significativas para el problema que resuelve la red. La mayor parte del aprendizaje profundo consiste en encadenar capas simples formando algo que puede verse como un proceso de \"destilación de datos\" progresiva.\n",
    "\n",
    "En este caso, la red consta de una secuencia de dos capas densas, que son capas neurales totalmente conectadas. La segunda (y última) capa es una capa \"softmax\" de 10 salidas, lo que significa que devolverá una matriz de 10 valores de probabilidad (que suman 1). Cada uno de estos valores será la probabilidad de que la imagen actual pertenezca a una de las 10 clases (los dígitos del 0 al 9).\n",
    "\n",
    "Hasta ahora solo hemos definido la estructura de la red, pero no hemos dado ninguna información acerca de cómo se llevará a cabo el entrenamiento. Para ello, hemos de indicarle a Keras algunas características adicionales, tales como el optimizador que permitirá modificar los pesos de la red, qué función objetivo (de error) se usará para dirigir esta optimización, y la métrica que usaremos para medir cómo se va comportando la red a medida que se entrena. Keras proporciona la función *compile* que permite establecer estas (y otras) propiedades sobre una red ya definida:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Observa que muchas de las ejecuciones que hacemos no proporcionan una salida imprimible, sino que modifican el contenido de ciertas variables para su ejecución posterior.\n",
    "\n",
    "Debido a que la red neuronal que vamos a usar debe recibir como dato de entrada cada imagen de forma aplanada (es decir, no como una matriz de 28x28, sino como un vector de 28x28=784 posiciones), nuestro primer paso es hacer uso de las instrucciones que proporciona Keras para transformar la forma de los datos de entrada. Además, aprovecharemos para normalizar el contenido de estas imágenes (están en escalas de grises con valores `uint8` entre 0 y 255, y las pasaremos a valores `float32` en [0,1]):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, vamos a convertir las etiquetas (que vienen en el dataset como valores enteros), en vectores binarios para que se corresponda con la salida que nuestra red va a proporcionar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proceso de entrenamiento\n",
    "\n",
    "Preparados los datos y definida la red (estructura y funcionalidad), podemos hacer uso de la instrucción *fit* para comenzar el proceso de entrenamiento sobre los datos que tenemos. Esencialmente, hemos de indicar sobre qué datos entrenar (entrada y salidas), cuántas iteraciones (epochs) y con qué tamaño de batch (cada cuántos ejemplos el algoritmos actualiza los pesos).\n",
    "\n",
    "Durante el proceso de entrenamiento, Keras informa de los valores que toma la función objetivo, así como de la/s métrica/s que hemos fijado en la compilación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.2609 - acc: 0.9246\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.1041 - acc: 0.9697\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.0681 - acc: 0.9799\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.0495 - acc: 0.9851\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.0367 - acc: 0.9891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e3d6444da0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observa que los valores mostrados son el error y métricas en los propios datos de entrenamiento, pero la labor de un modelo de aprendizaje es generalizar bien sobre datos que el proceso de entrenamiento no ha visto anteriormente, razón por la que tenemos un conjunto de test que nos permite evaluar cómo se comporta la red entrenada sobre ejemplos que no ha usado para ajustarse.\n",
    "\n",
    "ALcanzamos rápidamente una precisión de 0.989 (i.e. 98.9%) en el conjunto de entrenamiento, veamos cómo de bien se comporta con los datos de test (que no ha usado para aprender):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 73us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 0.9795\n"
     ]
    }
   ],
   "source": [
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Lo normal es que la red se comporte ligeramente peor en los datos de test que en los datos de entrenamiento, ya que el proceso de entrenamiento consiste precisamente en ajustar los pesos para que el error cometido en estos últimos se minimice. Esta diferencia de comportamiento entre entrenamiento y test se denomina **overfitting** (o **sobreajuste**). En todo caso, con una red tan simple como hemos usado, se alcanzan cotas del 98% de aciertos.\n",
    "\n",
    "Finalmente, podemos ver las predicciones que hace la red sobre algunos datos del conjunto de test (mostramos también las etiquetas aaociadas a los datos usados, pero ten en cuenta que están en formato binarizado, y el índice 1 corresponde a la etiqueta 0, el índice 2 a la etiqueta 1, etc...):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(network.predict(test_images[2:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[2:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
